{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1c8u0YQp1sVbYfK6/uPHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyangweng/Deep_Learning_Ittraining/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4MYDCDMcW3W",
        "outputId": "515d2782-ea1c-43fe-92dd-f29dfd841476"
      },
      "source": [
        "English_Character_Dataset = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "English_Character_Dataset\n",
        "character_list=[]\n",
        "\n",
        "for c in English_Character_Dataset:\n",
        "  character_list.append(c)\n",
        "\n",
        "\n",
        "\n",
        "char2index={}\n",
        "\n",
        "for index, c in enumerate(character_list):\n",
        "  char2index[c]=index\n",
        "\n",
        "\n",
        "print(f'len(character_list)={len(character_list)}')\n",
        "print(f'character_list={character_list}')\n",
        "print(f'char2indx={char2index}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(character_list)=26\n",
            "character_list=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "char2indx={'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh334M6_c-2L",
        "outputId": "f87e391c-85e4-441b-cd9e-5e82da6f7a36"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for index,c in enumerate(English_Character_Dataset):\n",
        "  if index != len(English_Character_Dataset)-1:\n",
        "    X.append(index)\n",
        "    y.append(index+1)\n",
        "\n",
        "  else:\n",
        "    print(f'忽略字元：{c}')\n",
        "\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "print('-'*50)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X=np.array(X)\n",
        "y=np.array(y)\n",
        "X=X/25\n",
        "X = X.reshape(-1,1,1)\n",
        "y = to_categorical(y)\n",
        "# print(X)\n",
        "# print(y)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "忽略字元：z\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
            "--------------------------------------------------\n",
            "(25, 1, 1)\n",
            "(25, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FDoR42gdXcC"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(LSTM(units=50,input_shape=(1,1),activation='relu',return_sequences=True))\n",
        "model.add(layers.LSTM(units=64,activation='relu'))\n",
        "model.add(layers.Dense(units=128,activation='relu'))\n",
        "model.add(layers.Dense(units=len(character_list),activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(\n",
        "  x=X,\n",
        "  y=y,\n",
        "  epochs=500,\n",
        "  batch_size=128,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "RBp8oIJFi51t",
        "outputId": "16a3e22c-aa69-4660-ba97-b43a8d2777f5"
      },
      "source": [
        "start_character = 'g'\n",
        "start_index = char2index[start_character]\n",
        "X_test=np.array(start_index )\n",
        "X_test=X_test/25\n",
        "X_test=X_test.reshape(-1,1,1)\n",
        "predict_confidence_matrix = model.predict(X_test)\n",
        "print(predict_confidence_matrix )\n",
        "predict_index = np.argmax(predict_confidence_matrix)\n",
        "predict_character = character_list[predict_index]\n",
        "predict_character"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00000000e+00 4.29630597e-26 4.20335600e-16 1.61720758e-11\n",
            "  3.48380169e-08 2.54112005e-04 9.55751985e-02 8.21314991e-01\n",
            "  8.24217796e-02 4.33474430e-04 3.93826610e-07 1.04587436e-10\n",
            "  5.70355405e-16 2.77492794e-20 2.22435948e-25 7.31850675e-32\n",
            "  3.82125239e-36 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'h'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XqxoWXXkyE-",
        "outputId": "749d79c1-b648-4f31-fec1-4d4f07b204c2"
      },
      "source": [
        "def predict_next_character(now_char):\n",
        "  X_test_index = char2index[now_char]\n",
        "  X_test = np.array([X_test_index])\n",
        "  X_test = X_test/25\n",
        "  X_test = X_test.reshape(-1,1,1)\n",
        "  next_char_confidence_array = model.predict(X_test)\n",
        "  next_char_confidence_array_index = np.argmax(next_char_confidence_array)\n",
        "  next_char = character_list[next_char_confidence_array_index]\n",
        "  return next_char\n",
        "\n",
        "start_character = 'a'\n",
        "now_char = start_character\n",
        "\n",
        "for i in range(25):\n",
        "  print(f'now_char={now_char}')\n",
        "  next_char = predict_next_character(now_char)\n",
        "  print(f'next_char={next_char}')\n",
        "  now_char = next_char"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now_char=a\n",
            "next_char=b\n",
            "now_char=b\n",
            "next_char=c\n",
            "now_char=c\n",
            "next_char=d\n",
            "now_char=d\n",
            "next_char=e\n",
            "now_char=e\n",
            "next_char=f\n",
            "now_char=f\n",
            "next_char=g\n",
            "now_char=g\n",
            "next_char=h\n",
            "now_char=h\n",
            "next_char=i\n",
            "now_char=i\n",
            "next_char=j\n",
            "now_char=j\n",
            "next_char=k\n",
            "now_char=k\n",
            "next_char=l\n",
            "now_char=l\n",
            "next_char=m\n",
            "now_char=m\n",
            "next_char=n\n",
            "now_char=n\n",
            "next_char=o\n",
            "now_char=o\n",
            "next_char=p\n",
            "now_char=p\n",
            "next_char=q\n",
            "now_char=q\n",
            "next_char=r\n",
            "now_char=r\n",
            "next_char=s\n",
            "now_char=s\n",
            "next_char=t\n",
            "now_char=t\n",
            "next_char=u\n",
            "now_char=u\n",
            "next_char=v\n",
            "now_char=v\n",
            "next_char=w\n",
            "now_char=w\n",
            "next_char=x\n",
            "now_char=x\n",
            "next_char=y\n",
            "now_char=y\n",
            "next_char=z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d-GkwEQk6UT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}